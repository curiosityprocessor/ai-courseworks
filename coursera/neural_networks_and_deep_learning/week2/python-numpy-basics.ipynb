{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c27674",
   "metadata": {},
   "source": [
    "# 1 Basic numpy functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79518764",
   "metadata": {},
   "source": [
    "## 1.1 sigmoid function, np.exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658d4333",
   "metadata": {},
   "source": [
    "### using math package to build basic sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f7864c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic sigmoid: 0.7310585786300049\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def basic_sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "print(\"basic sigmoid: \" + str(basic_sigmoid(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f53a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7dc824",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3] # when x is a list\n",
    "basic_sigmoid(x) # this fails because function expects a scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc45d9f",
   "metadata": {},
   "source": [
    "### using numpy package to build sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd48c3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy sigmoid: [0.73105858 0.88079708 0.95257413]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "x = np.array([1,2,3])\n",
    "print(\"numpy sigmoid: \" + str(sigmoid(x))) # function accepts scalar or numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38039d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "800e1027",
   "metadata": {},
   "source": [
    "## 1.2 Sigmoid Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9711d4a",
   "metadata": {},
   "source": [
    "with mathematical formula  \n",
    "$$sigmoid\\_derivative(x) = \\sigma'(x) = \\sigma(x) (1 - \\sigma(x))\\tag{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bf4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "x = np.array([1,2,3])\n",
    "print(\"sigmoid derivative: \" + str(sigmoid_derivative(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b404b4",
   "metadata": {},
   "source": [
    "## 1.3 reshaping arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25772264",
   "metadata": {},
   "source": [
    "`X.shape`: get the shape (dimension) of the matrix/vector X  \n",
    "`X.reshape()`: reshape the X into some other dimension  \n",
    "\n",
    "real life example:  \n",
    "- image is represented by 3 dimensional array $(length, height, depth = 3)$\n",
    "- when reading the image as input of algorithm, it is converted into vector of shape $(length * height * depth, 1)$\n",
    "- the 3D input is \"unrolled\" into 1D vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd18d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2vector(image):\n",
    "    shape = image.shape\n",
    "    return image.reshape(shape[0] * shape[1] * shape[2], 1)\n",
    "\n",
    "t_image = np.array([[[ 0.67826139,  0.29380381],\n",
    "                     [ 0.90714982,  0.52835647],\n",
    "                     [ 0.4215251 ,  0.45017551]],\n",
    "\n",
    "                   [[ 0.92814219,  0.96677647],\n",
    "                    [ 0.85304703,  0.52351845],\n",
    "                    [ 0.19981397,  0.27417313]],\n",
    "\n",
    "                   [[ 0.60659855,  0.00533165],\n",
    "                    [ 0.10820313,  0.49978937],\n",
    "                    [ 0.34144279,  0.94630077]]])\n",
    "print(\"image2vector(image): \" + str(image2vector(t_image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2405e117",
   "metadata": {},
   "source": [
    "## 1.4 Normalizing rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb150b",
   "metadata": {},
   "source": [
    "Normalizing data leads to better performance since gradient descent converges faster.  \n",
    "normalization: changing x to $\\frac{x}{\\|x\\|}$ (dividing each row vector of x by its norm)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba26eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_rows(x):\n",
    "    x_norm = np.linalg.norm(x, axis=1, keepdims=True)\n",
    "    return x / x_norm\n",
    "\n",
    "x = np.array([[0., 3., 4.],\n",
    "              [1., 6., 4.]])\n",
    "print(\"normalizeRows(x): \" + str(normalize_rows(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401ea3b8",
   "metadata": {},
   "source": [
    "### Softmax with numpy\n",
    "- $\\text{for } x \\in \\mathbb{R}^{1\\times n} \\text{,     }$\n",
    "\n",
    "\\begin{align*}\n",
    " softmax(x) &= softmax\\left(\\begin{bmatrix}\n",
    "    x_1  &&\n",
    "    x_2 &&\n",
    "    ...  &&\n",
    "    x_n  \n",
    "\\end{bmatrix}\\right) \\\\&= \\begin{bmatrix}\n",
    "    \\frac{e^{x_1}}{\\sum_{j}e^{x_j}}  &&\n",
    "    \\frac{e^{x_2}}{\\sum_{j}e^{x_j}}  &&\n",
    "    ...  &&\n",
    "    \\frac{e^{x_n}}{\\sum_{j}e^{x_j}} \n",
    "\\end{bmatrix} \n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "- $\\text{for a matrix } x \\in \\mathbb{R}^{m \\times n} \\text{,  $x_{ij}$ maps to the element in the $i^{th}$ row and $j^{th}$ column of $x$, thus we have: }$  \n",
    "\n",
    "\\begin{align*}\n",
    "softmax(x) &= softmax\\begin{bmatrix}\n",
    "            x_{11} & x_{12} & x_{13} & \\dots  & x_{1n} \\\\\n",
    "            x_{21} & x_{22} & x_{23} & \\dots  & x_{2n} \\\\\n",
    "            \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "            x_{m1} & x_{m2} & x_{m3} & \\dots  & x_{mn}\n",
    "            \\end{bmatrix} \\\\ \\\\&= \n",
    " \\begin{bmatrix}\n",
    "    \\frac{e^{x_{11}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{12}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{13}}}{\\sum_{j}e^{x_{1j}}} & \\dots  & \\frac{e^{x_{1n}}}{\\sum_{j}e^{x_{1j}}} \\\\\n",
    "    \\frac{e^{x_{21}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{22}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{23}}}{\\sum_{j}e^{x_{2j}}} & \\dots  & \\frac{e^{x_{2n}}}{\\sum_{j}e^{x_{2j}}} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\frac{e^{x_{m1}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m2}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m3}}}{\\sum_{j}e^{x_{mj}}} & \\dots  & \\frac{e^{x_{mn}}}{\\sum_{j}e^{x_{mj}}}\n",
    "\\end{bmatrix} \\\\ \\\\ &= \\begin{pmatrix}\n",
    "    softmax\\text{(first row of x)}  \\\\\n",
    "    softmax\\text{(second row of x)} \\\\\n",
    "    \\vdots  \\\\\n",
    "    softmax\\text{(last row of x)} \\\\\n",
    "\\end{pmatrix} \n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d0c457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5)\n",
      "(2, 1)\n",
      "softmax(x): [[9.80897665e-01 8.94462891e-04 1.79657674e-02 1.21052389e-04\n",
      "  1.21052389e-04]\n",
      " [8.78679856e-01 1.18916387e-01 8.01252314e-04 8.01252314e-04\n",
      "  8.01252314e-04]]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    x_exp = np.exp(x)\n",
    "    x_sum = np.sum(x_exp, axis=1, keepdims=True)\n",
    "    s = x_exp / x_sum\n",
    "    return s\n",
    "\n",
    "t_x = np.array([[9,2,5,0,0],\n",
    "                [7,5,0,0,0 ]])\n",
    "print(\"softmax(x): \" + str(softmax(t_x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99600da1",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "Vectorization is used to optimize working with very large datasets.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c7b7af",
   "metadata": {},
   "source": [
    "## 2.1 L1 and L2 loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28baf4",
   "metadata": {},
   "source": [
    "### L1 loss function\n",
    "$$\\begin{align*} & L_1(\\hat{y}, y) = \\sum_{i=0}^{m-1}|y^{(i)} - \\hat{y}^{(i)}| \\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b49e4613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1: 1.1\n"
     ]
    }
   ],
   "source": [
    "def L1(yhat, y):\n",
    "    loss = np.sum(np.abs(yhat - y))\n",
    "    return loss\n",
    "\n",
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L1: \" + str(L1(yhat, y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45682cf6",
   "metadata": {},
   "source": [
    "### L2 loss function\n",
    "$$\\begin{align*} & L_2(\\hat{y},y) = \\sum_{i=0}^{m-1}(y^{(i)} - \\hat{y}^{(i)})^2 \\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "873f403e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2:0.43\n"
     ]
    }
   ],
   "source": [
    "def L2(yhat, y):\n",
    "    loss = np.sum(np.dot(yhat - y, yhat - y))\n",
    "    return loss\n",
    "\n",
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "\n",
    "print(\"L2:\" + str(L2(yhat, y)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
